# TTEDNN for Rotor Angle Stability Prediction

This is a demo for power system rotor angle stability prediction using
TTEDNN based on the work (https://ieeexplore.ieee.org/document/10234142).

  * [TTEDNN for Rotor Angle Stability Prediction](#title)
      * [Prerequisites](#requist)
      * [Data Generation](#data_gen)
         * [Parameters Obtaining](#para)
         * [Simulation Process](#cal)
      * [TTEDNN](#ttednn)
         * [Graph Neural Network](#gnn)
         * [Temporal Convolution Network](#tcn)
         * [Model](#Model)
      * [Run](#run)
         * [Recommended Steps](#step)
         * [Others](#other)
            * [Training](#train)
            * [Visualization](#visual)
      * [References](#references)

## Prerequisites
1. For the simulation of second-order small-signal RAS and the establishment of TTEDNN model, the environment is Python 3.6.7. The packages used are listed in the **requirements.txt** file.
2. For the simulation of transient RAS, we use MATLAB 2019a. MATPOWER and Power System Toolbox (PST) are needed, they are available at https://matpower.org/download/ and https://www.ecse.rpi.edu/~chowj/.

## Data Generation
Two power system models simulation data is generated by Python `scipy` package and MATLAB PST toolbox correspondingly.

### Parameters Obtaining
The electrical parameters (power injections and admittance matrix) are obtained from MATPOWER 6.0, Power Flow Test Systems Repository (https://al-roomi.org/power-flow) and *Energy Function Analysis for Power System Stability* (https://doi.org/10.1007/978-1-4613-1635-0).

The file **data/data_to_original.m** can easily load parameters from MATPOWER
and save to your local machine.

We give a simple example of IEEE 14-bus system at **data/parameter/parameter14.h5**.

### Simulation Process
The **data/IEEE.py** file gives an example of the simulation of single-node disturbance case.

The uniform distribution
```python
def generate_uniform_init_array(Initial, init_num, node_num)
```
and Levy-stable distribution
```python
def generate_stable_init_array(Initial, init_num, node_num)
```
for initial states sampling are available.

We use `mpi4py` package to allow parallel computing.

## TTEDNN

### Graph Neural Network
We use the **spekral** package for Graph Neural Networks (GNNs), the detailed information could be found at https://github.com/danielegrattarola/spektral.

### Temporal Convolution Network
Based on the work presented in *Wavenet: A Generative Model for Raw Audio* and *An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling*, the Temporal Convolution module is composed of several residual blocks using 1D fully convolutional network (FCN) with casual and dilated convolution techniques. The Python code is at model/TCN.py.

### Model
Two models are conducted,
```python
def ttednn_keras
```
based on Keras Functional API, and
```python
class ttednn_tf
```
based on Keras model subclassing API.
You can see **nn.py** for more details.

## Run
### Recommended Steps
0. Download all pip requirements by:
   ```bash
   pip3 install -r requirements.txt
   ```

1. Download MATPOWER, and extract the downloaded ZIP file anywhere you like.
2. Start MATLAB and change your working directory to the MATPOWER directory you just extracted.
3. Run the installer:
   ```matlab
   install_matpower
   ```

4. Run **data_to_original.m** to save the electrical parameters.
5. Run **IEEE.py** to generate single-node perturbations data.
6. Run **trainer_keras.py** to train the TTEDNN model.
7. Run **visualization.py** to draw metrics during the traning process and the hidden layer activations.

### Others
1. *Training*

   Two training methods are provided.
   The **trainer_keras.py** gives the simple training method by using
   `model.fit` for a compiled Keras model.
   The **trainer_tf.py** gives the advanced training method that the training process can be customized by oneself.

2. *Visualization*

   Here we give a simple demo to visualize the training process and testing result.

   - 
      ```python
      def draw_training_curve(exp_num)
      ```
      plots the metrics of both accuracy and loss during the training process.
   - 
      ```python
      def hidden_layer(exp_num)
      ```
      plots the hidden layer visualization.


See **visualization.py** for details.

## References
1. https://arxiv.org/abs/1609.02907 (Semi-Supervised Classification with Graph Convolutional Networks)
2. https://arxiv.org/abs/1803.01271v2 (An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling)
3. https://github.com/danielegrattarola/spektral (GNNs for Tensorflow)
4. https://github.com/philipperemy/keras-tcn (TCN for Keras)
5. https://github.com/Baichenjia/Tensorflow-TCN (TCN for Tensorflow)
